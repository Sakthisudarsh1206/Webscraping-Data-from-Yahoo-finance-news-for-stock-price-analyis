# -*- coding: utf-8 -*-
"""Stock_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bvn3xSaDYVYSusFvpKVdSxuhM6-ubqhT
"""

# Importing the necessary libraries
from bs4 import BeautifulSoup
import requests

# URL of the website to be scraped
my_url = 'https://finance.yahoo.com/topic/stock-market-news/'
response = requests.get(my_url)

#Check response for error trapping and tracking
print("response.ok : {} , response.status_code : {}".format(response.ok , response.status_code))

#Scrape first n characters of html file
n= 500
print("Preview of response.text : ", response.text[:n])

def get_webpage(url):
    response= requests.get(url)
    if not response.ok:
      print(response.status_code)
      raise Exception("Failed to load page {}".format(url))
    page_content= response.text
    doc= BeautifulSoup(page_content,'html.parser')
    return doc

print("Preview of response.text : ", response.text[:500])

#finds title
doc=get_webpage(my_url)
doc.find('title')

div_tags= doc.find_all('div', {'class': "Ov(h) Pend(44px) Pstart(25px)"})

#to check the number of news items
len(div_tags)

print(div_tags[1])

print("Source: ", div_tags[1].find('div').text)
print("Head Line : {}".format(div_tags[1].find('a').text))

print("Image URL: ",div_tags[1].findParent().find('img')['src'])

#get the list of tags news info and put in python list ... we use helper function
def get_news_tags(doc):
    #Get the list of tags containing news information
    news_class = "Ov(h) Pend(44px) Pstart(25px)" # class name of div tag
    news_list  = doc.find_all('div', {'class': news_class})
    return news_list

BASE_URL = 'https://finance.yahoo.com' #Global Variable
#parse all indiviudal div tags and return as dictionary
def parse_news(news_tag):
    """Get the news data point and return dictionary"""
    news_source = news_tag.find('div').text #source
    news_headline = news_tag.find('a').text #heading
    news_url = news_tag.find('a')['href'] #link
    news_content = news_tag.find('p').text #content
    news_image = news_tag.findParent().find('img')['src'] #thumb image
    return { 'source' : news_source,
            'headline' : news_headline,
            'url' : BASE_URL + news_url,
            'content' : news_content,
            'image' : news_image
           }

import pandas as pd

"""Letâ€™s create a wrapper function, The first step is to use the get_page function to download the HTML page, then we can pass the output in get_news_tags to identify a list of <div> tags for news.

After that we will use a List Comprehension technique to parse each <div> tag using parse_news, the output will be in the form of lists of dictionaries.

Finally, we will use the .DataFrame() method to create pandas dataframe and use the to_csv function to store required data in CSV format.
"""

def scrape_news(url, path=None):
    """Get the yahoo finance market news and write them to CSV file """
    if path is None:
        path = 'stocknews.csv'

    print('Requesting html page')
    doc = get_page(url)

    print('Extracting news tags')
    news_list = get_news_tags(doc)

    print('Parsing news tags')
    news_data = [parse_news(news_tag) for news_tag in news_list]

    print('Save the data to a CSV')
    news_df = pd.DataFrame(news_data)
    news_df.to_csv(path, index=None)

    #This return statement is optional, we are doing this just analyze the final output
    return news_df

YAHOO_NEWS_URL = BASE_URL+'/topic/stock-market-news/'
news_df = scrape_news(YAHOO_NEWS_URL)